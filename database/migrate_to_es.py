"""
SQLiteåˆ°Elasticsearchæ•°æ®è¿ç§»å·¥å…·

æä¾›å‘½ä»¤è¡Œå·¥å…·ç”¨äºå°†ç°æœ‰SQLiteæ•°æ®è¿ç§»åˆ°Elasticsearchã€‚
æ”¯æŒå¢é‡è¿ç§»ã€æ•°æ®éªŒè¯å’Œå›æ»šã€‚

ä½¿ç”¨æ–¹æ³•:
    python -m database.migrate_to_es --source ./data/chatcompass.db --validate

ä½œè€…: ChatCompass Team
ç‰ˆæœ¬: v1.2.2
"""

import argparse
import sys
import sqlite3
import logging
from typing import Tuple, Dict, Any
from pathlib import Path
from datetime import datetime
from .es_manager import ElasticsearchManager
from .sqlite_manager import SQLiteManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataMigrator:
    """æ•°æ®è¿ç§»å™¨"""
    
    def __init__(self, sqlite_path: str, es_host: str = "localhost",
                 es_port: int = 9200, index_prefix: str = "chatcompass"):
        """
        åˆå§‹åŒ–è¿ç§»å™¨
        
        Args:
            sqlite_path: SQLiteæ•°æ®åº“è·¯å¾„
            es_host: Elasticsearchä¸»æœº
            es_port: Elasticsearchç«¯å£
            index_prefix: ESç´¢å¼•å‰ç¼€
        """
        self.sqlite_path = sqlite_path
        
        # æ£€æŸ¥SQLiteæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(sqlite_path).exists():
            raise FileNotFoundError(f"SQLiteæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {sqlite_path}")
        
        # åˆå§‹åŒ–ç®¡ç†å™¨
        try:
            self.sqlite_mgr = SQLiteManager(sqlite_path)
            self.es_mgr = ElasticsearchManager(
                host=es_host,
                port=es_port,
                index_prefix=index_prefix
            )
            logger.info("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def migrate_all(self, validate: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´æ•°æ®è¿ç§»
        
        Args:
            validate: æ˜¯å¦åœ¨è¿ç§»åéªŒè¯æ•°æ®
        
        Returns:
            è¿ç§»ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ•°æ®è¿ç§»: SQLite â†’ Elasticsearch")
        logger.info("=" * 60)
        
        start_time = datetime.now()
        stats = {
            'start_time': start_time.isoformat(),
            'conversations': 0,
            'messages': 0,
            'tags': 0,
            'errors': []
        }
        
        try:
            # 1. è¿ç§»æ ‡ç­¾
            logger.info("\nğŸ“‹ Step 1/3: è¿ç§»æ ‡ç­¾...")
            stats['tags'] = self._migrate_tags()
            logger.info(f"âœ… æ ‡ç­¾è¿ç§»å®Œæˆ: {stats['tags']}ä¸ª")
            
            # 2. è¿ç§»å¯¹è¯
            logger.info("\nğŸ’¬ Step 2/3: è¿ç§»å¯¹è¯...")
            stats['conversations'] = self._migrate_conversations()
            logger.info(f"âœ… å¯¹è¯è¿ç§»å®Œæˆ: {stats['conversations']}ä¸ª")
            
            # 3. è¿ç§»æ¶ˆæ¯
            logger.info("\nğŸ“¨ Step 3/3: è¿ç§»æ¶ˆæ¯...")
            stats['messages'] = self._migrate_messages()
            logger.info(f"âœ… æ¶ˆæ¯è¿ç§»å®Œæˆ: {stats['messages']}æ¡")
            
            # éªŒè¯æ•°æ®
            if validate:
                logger.info("\nğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")
                validation_result = self.validate_migration()
                stats['validation'] = validation_result
                
                if validation_result['status'] == 'success':
                    logger.info("âœ… æ•°æ®éªŒè¯é€šè¿‡")
                else:
                    logger.warning(f"âš ï¸ æ•°æ®éªŒè¯è­¦å‘Š: {validation_result['message']}")
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            stats['end_time'] = end_time.isoformat()
            stats['duration_seconds'] = duration
            stats['status'] = 'success'
            
            logger.info("\n" + "=" * 60)
            logger.info("âœ… æ•°æ®è¿ç§»å®Œæˆï¼")
            logger.info(f"â±ï¸  æ€»è€—æ—¶: {duration:.2f}ç§’")
            logger.info(f"ğŸ“Š è¿ç§»ç»Ÿè®¡:")
            logger.info(f"   - å¯¹è¯: {stats['conversations']}ä¸ª")
            logger.info(f"   - æ¶ˆæ¯: {stats['messages']}æ¡")
            logger.info(f"   - æ ‡ç­¾: {stats['tags']}ä¸ª")
            logger.info("=" * 60)
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è¿ç§»å¤±è´¥: {e}")
            stats['status'] = 'failed'
            stats['error'] = str(e)
            return stats
    
    def _migrate_tags(self) -> int:
        """è¿ç§»æ ‡ç­¾"""
        try:
            conn = sqlite3.connect(self.sqlite_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute("SELECT * FROM tags")
            tags = cursor.fetchall()
            
            count = 0
            for tag in tags:
                tag_dict = {
                    'tag_id': tag['tag_id'],
                    'name': tag['name'],
                    'color': tag.get('color', '#3b82f6'),
                    'description': tag.get('description', '')
                }
                
                if self.es_mgr.save_tag(**tag_dict):
                    count += 1
            
            conn.close()
            return count
            
        except Exception as e:
            logger.error(f"âŒ æ ‡ç­¾è¿ç§»å¤±è´¥: {e}")
            return 0
    
    def _migrate_conversations(self) -> int:
        """è¿ç§»å¯¹è¯"""
        try:
            conn = sqlite3.connect(self.sqlite_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # è·å–å¯¹è¯åŠå…¶æ ‡ç­¾
            cursor.execute("""
                SELECT c.*, GROUP_CONCAT(ct.tag_id) as tag_ids
                FROM conversations c
                LEFT JOIN conversation_tags ct ON c.conversation_id = ct.conversation_id
                GROUP BY c.conversation_id
            """)
            conversations = cursor.fetchall()
            
            count = 0
            for conv in conversations:
                conv_dict = {
                    'conversation_id': conv['conversation_id'],
                    'title': conv['title'],
                    'platform': conv['platform'],
                    'create_time': conv['create_time'],
                    'message_count': conv.get('message_count', 0),
                    'total_tokens': conv.get('total_tokens', 0),
                    'model': conv.get('model', ''),
                    'summary': conv.get('summary', ''),
                    'category': conv.get('category', ''),
                    'tags': conv['tag_ids'].split(',') if conv['tag_ids'] else []
                }
                
                if self.es_mgr.save_conversation(**conv_dict):
                    count += 1
                    
                    if count % 100 == 0:
                        logger.info(f"   å·²è¿ç§»: {count}ä¸ªå¯¹è¯...")
            
            conn.close()
            return count
            
        except Exception as e:
            logger.error(f"âŒ å¯¹è¯è¿ç§»å¤±è´¥: {e}")
            return 0
    
    def _migrate_messages(self) -> int:
        """è¿ç§»æ¶ˆæ¯ï¼ˆæ‰¹é‡ï¼‰"""
        try:
            conn = sqlite3.connect(self.sqlite_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) as total FROM messages")
            total = cursor.fetchone()['total']
            logger.info(f"   æ€»æ¶ˆæ¯æ•°: {total}æ¡")
            
            # åˆ†æ‰¹è¿ç§»ï¼Œæ¯æ‰¹1000æ¡
            batch_size = 1000
            offset = 0
            total_migrated = 0
            
            while True:
                cursor.execute(f"""
                    SELECT * FROM messages
                    ORDER BY conversation_id, order_index
                    LIMIT {batch_size} OFFSET {offset}
                """)
                messages = cursor.fetchall()
                
                if not messages:
                    break
                
                # å‡†å¤‡æ‰¹é‡æ•°æ®
                batch_data = []
                for msg in messages:
                    msg_dict = {
                        'message_id': msg['message_id'],
                        'conversation_id': msg['conversation_id'],
                        'role': msg['role'],
                        'content': msg['content'],
                        'create_time': msg['create_time'],
                        'order_index': msg.get('order_index', 0),
                        'parent_message_id': msg.get('parent_message_id', ''),
                        'tokens': msg.get('tokens', 0)
                    }
                    batch_data.append(msg_dict)
                
                # æ‰¹é‡ä¿å­˜
                migrated = self.es_mgr.bulk_save_messages(batch_data)
                total_migrated += migrated
                
                logger.info(f"   è¿›åº¦: {total_migrated}/{total} ({total_migrated*100//total}%)")
                
                offset += batch_size
            
            conn.close()
            return total_migrated
            
        except Exception as e:
            logger.error(f"âŒ æ¶ˆæ¯è¿ç§»å¤±è´¥: {e}")
            return 0
    
    def validate_migration(self) -> Dict[str, Any]:
        """éªŒè¯è¿ç§»æ•°æ®çš„å®Œæ•´æ€§"""
        try:
            # è·å–SQLiteç»Ÿè®¡
            conn = sqlite3.connect(self.sqlite_path)
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM conversations")
            sqlite_conv_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM messages")
            sqlite_msg_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM tags")
            sqlite_tag_count = cursor.fetchone()[0]
            
            conn.close()
            
            # è·å–ESç»Ÿè®¡
            es_stats = self.es_mgr.get_statistics()
            
            # å¯¹æ¯”æ•°æ®
            conv_match = sqlite_conv_count == es_stats.get('total_conversations', 0)
            msg_match = sqlite_msg_count == es_stats.get('total_messages', 0)
            tag_match = sqlite_tag_count == es_stats.get('total_tags', 0)
            
            all_match = conv_match and msg_match and tag_match
            
            result = {
                'status': 'success' if all_match else 'mismatch',
                'sqlite': {
                    'conversations': sqlite_conv_count,
                    'messages': sqlite_msg_count,
                    'tags': sqlite_tag_count
                },
                'elasticsearch': {
                    'conversations': es_stats.get('total_conversations', 0),
                    'messages': es_stats.get('total_messages', 0),
                    'tags': es_stats.get('total_tags', 0)
                },
                'match': {
                    'conversations': conv_match,
                    'messages': msg_match,
                    'tags': tag_match
                }
            }
            
            if not all_match:
                mismatches = []
                if not conv_match:
                    mismatches.append('å¯¹è¯æ•°é‡ä¸åŒ¹é…')
                if not msg_match:
                    mismatches.append('æ¶ˆæ¯æ•°é‡ä¸åŒ¹é…')
                if not tag_match:
                    mismatches.append('æ ‡ç­¾æ•°é‡ä¸åŒ¹é…')
                result['message'] = ', '.join(mismatches)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def incremental_migrate(self, since: str) -> Dict[str, Any]:
        """
        å¢é‡è¿ç§»ï¼ˆè¿ç§»æŒ‡å®šæ—¶é—´åçš„æ•°æ®ï¼‰
        
        Args:
            since: èµ·å§‹æ—¶é—´ (ISOæ ¼å¼)
        """
        logger.info(f"å¼€å§‹å¢é‡è¿ç§»: since {since}")
        
        try:
            conn = sqlite3.connect(self.sqlite_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # å¢é‡è¿ç§»å¯¹è¯
            cursor.execute("""
                SELECT * FROM conversations
                WHERE update_time >= ?
                ORDER BY update_time
            """, (since,))
            conversations = cursor.fetchall()
            
            conv_count = 0
            for conv in conversations:
                conv_dict = dict(conv)
                if self.es_mgr.save_conversation(**conv_dict):
                    conv_count += 1
            
            # å¢é‡è¿ç§»æ¶ˆæ¯
            cursor.execute("""
                SELECT m.* FROM messages m
                JOIN conversations c ON m.conversation_id = c.conversation_id
                WHERE c.update_time >= ?
                ORDER BY m.create_time
            """, (since,))
            messages = cursor.fetchall()
            
            msg_list = [dict(msg) for msg in messages]
            msg_count = self.es_mgr.bulk_save_messages(msg_list)
            
            conn.close()
            
            logger.info(f"âœ… å¢é‡è¿ç§»å®Œæˆ: {conv_count}ä¸ªå¯¹è¯, {msg_count}æ¡æ¶ˆæ¯")
            
            return {
                'status': 'success',
                'conversations': conv_count,
                'messages': msg_count,
                'since': since
            }
            
        except Exception as e:
            logger.error(f"âŒ å¢é‡è¿ç§»å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="ChatCompassæ•°æ®è¿ç§»å·¥å…·: SQLite â†’ Elasticsearch"
    )
    
    parser.add_argument(
        '--source',
        type=str,
        required=True,
        help='SQLiteæ•°æ®åº“è·¯å¾„'
    )
    
    parser.add_argument(
        '--es-host',
        type=str,
        default='localhost',
        help='Elasticsearchä¸»æœºåœ°å€ (é»˜è®¤: localhost)'
    )
    
    parser.add_argument(
        '--es-port',
        type=int,
        default=9200,
        help='Elasticsearchç«¯å£ (é»˜è®¤: 9200)'
    )
    
    parser.add_argument(
        '--index-prefix',
        type=str,
        default='chatcompass',
        help='ESç´¢å¼•å‰ç¼€ (é»˜è®¤: chatcompass)'
    )
    
    parser.add_argument(
        '--validate',
        action='store_true',
        help='è¿ç§»åéªŒè¯æ•°æ®å®Œæ•´æ€§'
    )
    
    parser.add_argument(
        '--incremental',
        type=str,
        help='å¢é‡è¿ç§»: ä»…è¿ç§»æ­¤æ—¶é—´åçš„æ•°æ® (ISOæ ¼å¼: 2024-01-01T00:00:00)'
    )
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºè¿ç§»å™¨
        migrator = DataMigrator(
            sqlite_path=args.source,
            es_host=args.es_host,
            es_port=args.es_port,
            index_prefix=args.index_prefix
        )
        
        # æ‰§è¡Œè¿ç§»
        if args.incremental:
            result = migrator.incremental_migrate(args.incremental)
        else:
            result = migrator.migrate_all(validate=args.validate)
        
        # è¾“å‡ºç»“æœ
        if result['status'] == 'success':
            logger.info("\nâœ… è¿ç§»æˆåŠŸå®Œæˆï¼")
            sys.exit(0)
        else:
            logger.error(f"\nâŒ è¿ç§»å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
