"""
AIæœåŠ¡ç®¡ç†å™¨

ç»Ÿä¸€ç®¡ç†AIåˆ†æåŠŸèƒ½ï¼Œæ”¯æŒå¤šç§AIåç«¯ï¼ˆOllamaã€OpenAIç­‰ï¼‰
æä¾›å¯¹è¯æ‘˜è¦ã€æ ‡ç­¾æå–ã€è‡ªåŠ¨åˆ†ç±»ç­‰åŠŸèƒ½ã€‚

ä½œè€…: ChatCompass Team
ç‰ˆæœ¬: v1.2.2
"""

import os
import logging
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, asdict
from .ollama_client import OllamaClient, AIAnalysisResult

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class AIConfig:
    """AIæœåŠ¡é…ç½®"""
    enabled: bool = True
    backend: str = "ollama"  # ollama, openai, deepseek
    ollama_host: str = "http://localhost:11434"
    ollama_model: str = "qwen2.5:3b"
    timeout: int = 60
    auto_analyze: bool = False  # æ˜¯å¦è‡ªåŠ¨åˆ†ææ–°å¯¹è¯
    
    @classmethod
    def from_env(cls) -> 'AIConfig':
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        return cls(
            enabled=os.getenv('AI_ENABLED', 'true').lower() == 'true',
            backend=os.getenv('AI_BACKEND', 'ollama'),
            ollama_host=os.getenv('OLLAMA_HOST', 'http://localhost:11434'),
            ollama_model=os.getenv('OLLAMA_MODEL', 'qwen2.5:3b'),
            timeout=int(os.getenv('AI_TIMEOUT', '60')),
            auto_analyze=os.getenv('AI_AUTO_ANALYZE', 'false').lower() == 'true'
        )


class AIService:
    """AIæœåŠ¡ç®¡ç†å™¨"""
    
    def __init__(self, config: Optional[AIConfig] = None):
        """
        åˆå§‹åŒ–AIæœåŠ¡
        
        Args:
            config: AIé…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.config = config or AIConfig.from_env()
        self.client = None
        
        if self.config.enabled:
            self._initialize_client()
    
    def _initialize_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        try:
            if self.config.backend == 'ollama':
                self.client = OllamaClient(
                    base_url=self.config.ollama_host,
                    model=self.config.ollama_model,
                    timeout=self.config.timeout
                )
                logger.info(f"âœ… Ollamaå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {self.config.ollama_model}")
            
            elif self.config.backend == 'openai':
                from .openai_client import OpenAIClient
                self.client = OpenAIClient()
                logger.info("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            elif self.config.backend == 'deepseek':
                from .openai_client import DeepSeekClient
                self.client = DeepSeekClient()
                logger.info("âœ… DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„AIåç«¯: {self.config.backend}")
        
        except Exception as e:
            logger.error(f"âŒ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.config.enabled = False
    
    def is_available(self) -> bool:
        """æ£€æŸ¥AIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        if not self.config.enabled or not self.client:
            return False
        
        try:
            if isinstance(self.client, OllamaClient):
                return self.client.is_available()
            else:
                # å…¶ä»–å®¢æˆ·ç«¯çš„æ£€æŸ¥é€»è¾‘
                return True
        except:
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–AIæœåŠ¡çŠ¶æ€"""
        status = {
            'enabled': self.config.enabled,
            'backend': self.config.backend,
            'available': False,
            'model': None,
            'available_models': []
        }
        
        if not self.config.enabled:
            status['message'] = 'AIåŠŸèƒ½æœªå¯ç”¨'
            return status
        
        if not self.client:
            status['message'] = 'AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–'
            return status
        
        try:
            status['available'] = self.is_available()
            
            if isinstance(self.client, OllamaClient):
                status['model'] = self.client.model
                if status['available']:
                    status['available_models'] = self.client.list_models()
            
            status['message'] = 'AIæœåŠ¡æ­£å¸¸' if status['available'] else 'AIæœåŠ¡ä¸å¯ç”¨'
        
        except Exception as e:
            status['message'] = f'çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}'
        
        return status
    
    def analyze_conversation(self, 
                            conversation_text: str,
                            title: str = "") -> Optional[AIAnalysisResult]:
        """
        åˆ†æå¯¹è¯å†…å®¹
        
        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            title: å¯¹è¯æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            AIAnalysisResultå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.config.enabled:
            logger.warning("AIåŠŸèƒ½æœªå¯ç”¨")
            return None
        
        if not self.is_available():
            logger.warning("AIæœåŠ¡ä¸å¯ç”¨")
            return None
        
        try:
            logger.info(f"å¼€å§‹åˆ†æå¯¹è¯{f': {title}' if title else ''}...")
            
            # è°ƒç”¨AIåˆ†æ
            result = self.client.analyze_conversation(conversation_text)
            
            logger.info(f"âœ… åˆ†æå®Œæˆ: {result.category} | ç½®ä¿¡åº¦: {result.confidence}")
            logger.debug(f"   æ‘˜è¦: {result.summary[:50]}...")
            logger.debug(f"   æ ‡ç­¾: {', '.join(result.tags)}")
            
            return result
        
        except TimeoutError as e:
            logger.error(f"âŒ åˆ†æè¶…æ—¶: {e}")
            return None
        
        except Exception as e:
            logger.error(f"âŒ åˆ†æå¤±è´¥: {e}")
            return None
    
    def generate_summary(self, 
                        conversation_text: str,
                        max_words: int = 150) -> Optional[str]:
        """
        å¿«é€Ÿç”Ÿæˆæ‘˜è¦ï¼ˆä¸åŒ…å«åˆ†ç±»å’Œæ ‡ç­¾ï¼‰
        
        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            max_words: æœ€å¤§å­—æ•°
        
        Returns:
            æ‘˜è¦æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.is_available():
            return None
        
        try:
            if isinstance(self.client, OllamaClient):
                return self.client.generate_summary_only(conversation_text, max_words)
            else:
                # å…¶ä»–å®¢æˆ·ç«¯ä½¿ç”¨å®Œæ•´åˆ†æ
                result = self.analyze_conversation(conversation_text)
                return result.summary if result else None
        
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
            return None
    
    def generate_tags(self,
                     conversation_text: str,
                     num_tags: int = 5) -> Optional[List[str]]:
        """
        å¿«é€Ÿç”Ÿæˆæ ‡ç­¾
        
        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            num_tags: æ ‡ç­¾æ•°é‡
        
        Returns:
            æ ‡ç­¾åˆ—è¡¨ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.is_available():
            return None
        
        try:
            if isinstance(self.client, OllamaClient):
                return self.client.generate_tags_only(conversation_text, num_tags)
            else:
                # å…¶ä»–å®¢æˆ·ç«¯ä½¿ç”¨å®Œæ•´åˆ†æ
                result = self.analyze_conversation(conversation_text)
                return result.tags if result else None
        
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ ‡ç­¾å¤±è´¥: {e}")
            return None
    
    def batch_analyze(self,
                     conversations: List[Dict[str, str]],
                     callback=None) -> List[Optional[AIAnalysisResult]]:
        """
        æ‰¹é‡åˆ†æå¯¹è¯
        
        Args:
            conversations: å¯¹è¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'text' å’Œå¯é€‰çš„ 'title'
            callback: è¿›åº¦å›è°ƒå‡½æ•° callback(current, total)
        
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total = len(conversations)
        
        for i, conv in enumerate(conversations, 1):
            text = conv.get('text', '')
            title = conv.get('title', '')
            
            result = self.analyze_conversation(text, title)
            results.append(result)
            
            if callback:
                callback(i, total)
        
        return results
    
    def pull_model(self, model_name: str = None) -> bool:
        """
        ä¸‹è½½Ollamaæ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„æ¨¡å‹
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not isinstance(self.client, OllamaClient):
            logger.error("åªæœ‰Ollamaåç«¯æ”¯æŒä¸‹è½½æ¨¡å‹")
            return False
        
        import requests
        
        model = model_name or self.config.ollama_model
        
        try:
            logger.info(f"å¼€å§‹ä¸‹è½½æ¨¡å‹: {model}...")
            
            url = f"{self.config.ollama_host}/api/pull"
            response = requests.post(
                url,
                json={"name": model},
                stream=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            for line in response.iter_lines():
                if line:
                    import json
                    data = json.loads(line)
                    status = data.get('status', '')
                    
                    if 'total' in data and 'completed' in data:
                        percent = (data['completed'] / data['total']) * 100
                        logger.info(f"ä¸‹è½½è¿›åº¦: {percent:.1f}%")
                    else:
                        logger.info(status)
            
            logger.info(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model}")
            return True
        
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def test_connection(self) -> Dict[str, Any]:
        """
        æµ‹è¯•AIè¿æ¥
        
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        result = {
            'success': False,
            'backend': self.config.backend,
            'message': '',
            'test_response': None
        }
        
        if not self.is_available():
            result['message'] = 'AIæœåŠ¡ä¸å¯ç”¨'
            return result
        
        try:
            # ç®€å•æµ‹è¯•
            test_text = "ç”¨æˆ·: ä½ å¥½\nåŠ©æ‰‹: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"
            
            logger.info("æ‰§è¡Œè¿æ¥æµ‹è¯•...")
            response = self.client.generate_summary_only(test_text, max_words=20)
            
            if response:
                result['success'] = True
                result['message'] = 'AIæœåŠ¡è¿æ¥æ­£å¸¸'
                result['test_response'] = response
                logger.info("âœ… è¿æ¥æµ‹è¯•æˆåŠŸ")
            else:
                result['message'] = 'AIæœåŠ¡æ— å“åº”'
                logger.warning("âš ï¸ è¿æ¥æµ‹è¯•å¤±è´¥ï¼šæ— å“åº”")
        
        except Exception as e:
            result['message'] = f'è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}'
            logger.error(f"âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        
        return result


# å…¨å±€AIæœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_ai_service_instance = None


def get_ai_service() -> AIService:
    """è·å–å…¨å±€AIæœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _ai_service_instance
    
    if _ai_service_instance is None:
        _ai_service_instance = AIService()
    
    return _ai_service_instance


def reset_ai_service():
    """é‡ç½®å…¨å±€AIæœåŠ¡å®ä¾‹ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _ai_service_instance
    _ai_service_instance = None


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    import sys
    
    # åˆ›å»ºAIæœåŠ¡
    ai_service = AIService()
    
    # æ£€æŸ¥çŠ¶æ€
    status = ai_service.get_status()
    print(f"\n{'='*60}")
    print("AIæœåŠ¡çŠ¶æ€")
    print(f"{'='*60}")
    for key, value in status.items():
        print(f"{key}: {value}")
    print(f"{'='*60}\n")
    
    if not status['available']:
        print("âŒ AIæœåŠ¡ä¸å¯ç”¨ï¼Œé€€å‡ºæµ‹è¯•")
        sys.exit(1)
    
    # æµ‹è¯•è¿æ¥
    test_result = ai_service.test_connection()
    print(f"\nè¿æ¥æµ‹è¯•: {'âœ… æˆåŠŸ' if test_result['success'] else 'âŒ å¤±è´¥'}")
    print(f"æ¶ˆæ¯: {test_result['message']}")
    if test_result['test_response']:
        print(f"æµ‹è¯•å“åº”: {test_result['test_response']}")
    
    # æµ‹è¯•åˆ†æ
    test_conversation = """
ç”¨æˆ·: æˆ‘æƒ³å­¦ä¹ Pythonæ•°æ®åˆ†æï¼Œåº”è¯¥ä»å“ªé‡Œå¼€å§‹ï¼Ÿ

åŠ©æ‰‹: å­¦ä¹ Pythonæ•°æ®åˆ†æï¼Œæˆ‘å»ºè®®ï¼š
1. æŒæ¡PythonåŸºç¡€è¯­æ³•
2. å­¦ä¹ NumPyå’ŒPandas
3. äº†è§£æ•°æ®å¯è§†åŒ–
4. å®è·µçœŸå®é¡¹ç›®

ç”¨æˆ·: Pandasæœ‰å“ªäº›å¸¸ç”¨æ“ä½œï¼Ÿ

åŠ©æ‰‹: Pandaså¸¸ç”¨æ“ä½œåŒ…æ‹¬ï¼š
- æ•°æ®è¯»å–: read_csv(), read_excel()
- æ•°æ®ç­›é€‰: loc[], iloc[]
- æ•°æ®æ¸…æ´—: dropna(), fillna()
- æ•°æ®èšåˆ: groupby(), agg()
"""
    
    print(f"\n{'='*60}")
    print("å¯¹è¯åˆ†ææµ‹è¯•")
    print(f"{'='*60}")
    
    result = ai_service.analyze_conversation(test_conversation, "Pythonæ•°æ®åˆ†æå­¦ä¹ ")
    
    if result:
        print(f"\nğŸ“ æ‘˜è¦:\n{result.summary}")
        print(f"\nğŸ“ åˆ†ç±»: {result.category}")
        print(f"\nğŸ·ï¸  æ ‡ç­¾: {', '.join(result.tags)}")
        print(f"\nğŸ“Š ç½®ä¿¡åº¦: {result.confidence}")
    else:
        print("âŒ åˆ†æå¤±è´¥")
    
    print(f"\n{'='*60}\n")
