"""
Elasticsearchæ•°æ®åº“ç®¡ç†å™¨

å®ç°åŸºäºElasticsearchçš„æ•°æ®å­˜å‚¨å’Œæœç´¢åŠŸèƒ½ã€‚
æ”¯æŒä¸­æ–‡åˆ†è¯ã€å…¨æ–‡æœç´¢ã€å‘é‡æœç´¢ç­‰é«˜çº§åŠŸèƒ½ã€‚

ä½œè€…: ChatCompass Team
ç‰ˆæœ¬: v1.2.2
"""

from typing import List, Dict, Optional, Any, Tuple
from datetime import datetime
from elasticsearch import Elasticsearch, helpers
from elasticsearch.exceptions import NotFoundError, ConnectionError as ESConnectionError
import logging
import os
from .base_storage import BaseStorage

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ElasticsearchManager(BaseStorage):
    """Elasticsearchå­˜å‚¨å®ç°"""

    def __init__(self, host: str = "localhost", port: int = 9200,
                 index_prefix: str = "chatcompass",
                 username: Optional[str] = None,
                 password: Optional[str] = None):
        """
        åˆå§‹åŒ–Elasticsearchè¿æ¥
        
        Args:
            host: ESä¸»æœºåœ°å€
            port: ESç«¯å£
            index_prefix: ç´¢å¼•åç§°å‰ç¼€
            username: ç”¨æˆ·åï¼ˆå¯é€‰ï¼‰
            password: å¯†ç ï¼ˆå¯é€‰ï¼‰
        """
        # æ„å»ºè¿æ¥é…ç½®
        es_config = {
            'hosts': [f'{host}:{port}'],
            'retry_on_timeout': True,
            'max_retries': 3,
            'timeout': 30
        }
        
        # æ·»åŠ è®¤è¯ä¿¡æ¯
        if username and password:
            es_config['http_auth'] = (username, password)
        
        try:
            self.es = Elasticsearch(**es_config)
            
            # æ£€æŸ¥è¿æ¥
            if not self.es.ping():
                raise ESConnectionError("æ— æ³•è¿æ¥åˆ°Elasticsearch")
            
            logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°Elasticsearch {host}:{port}")
            
        except Exception as e:
            logger.error(f"âŒ Elasticsearchè¿æ¥å¤±è´¥: {e}")
            raise
        
        self.index_prefix = index_prefix
        self.conversation_index = f"{index_prefix}_conversations"
        self.message_index = f"{index_prefix}_messages"
        self.tag_index = f"{index_prefix}_tags"
        
        # åˆå§‹åŒ–ç´¢å¼•
        self._create_indices()
    
    def _create_indices(self):
        """åˆ›å»ºElasticsearchç´¢å¼•å’Œæ˜ å°„"""
        
        # Conversationsç´¢å¼•æ˜ å°„
        conversation_mapping = {
            "settings": {
                "number_of_shards": 1,
                "number_of_replicas": 0,
                "analysis": {
                    "analyzer": {
                        "ik_smart_analyzer": {
                            "type": "custom",
                            "tokenizer": "ik_smart"
                        },
                        "ik_max_word_analyzer": {
                            "type": "custom",
                            "tokenizer": "ik_max_word"
                        }
                    }
                }
            },
            "mappings": {
                "properties": {
                    "conversation_id": {"type": "keyword"},
                    "title": {
                        "type": "text",
                        "analyzer": "ik_max_word_analyzer",
                        "search_analyzer": "ik_smart_analyzer",
                        "fields": {
                            "keyword": {"type": "keyword"}
                        }
                    },
                    "platform": {"type": "keyword"},
                    "create_time": {"type": "date"},
                    "update_time": {"type": "date"},
                    "message_count": {"type": "integer"},
                    "total_tokens": {"type": "integer"},
                    "model": {"type": "keyword"},
                    "tags": {"type": "keyword"},
                    "summary": {
                        "type": "text",
                        "analyzer": "ik_max_word_analyzer",
                        "search_analyzer": "ik_smart_analyzer"
                    },
                    "category": {"type": "keyword"}
                }
            }
        }
        
        # Messagesç´¢å¼•æ˜ å°„
        message_mapping = {
            "settings": {
                "number_of_shards": 1,
                "number_of_replicas": 0,
                "analysis": {
                    "analyzer": {
                        "ik_smart_analyzer": {
                            "type": "custom",
                            "tokenizer": "ik_smart"
                        },
                        "ik_max_word_analyzer": {
                            "type": "custom",
                            "tokenizer": "ik_max_word"
                        }
                    }
                }
            },
            "mappings": {
                "properties": {
                    "message_id": {"type": "keyword"},
                    "conversation_id": {"type": "keyword"},
                    "role": {"type": "keyword"},
                    "content": {
                        "type": "text",
                        "analyzer": "ik_max_word_analyzer",
                        "search_analyzer": "ik_smart_analyzer"
                    },
                    "create_time": {"type": "date"},
                    "order_index": {"type": "integer"},
                    "parent_message_id": {"type": "keyword"},
                    "tokens": {"type": "integer"}
                }
            }
        }
        
        # Tagsç´¢å¼•æ˜ å°„
        tag_mapping = {
            "settings": {
                "number_of_shards": 1,
                "number_of_replicas": 0
            },
            "mappings": {
                "properties": {
                    "tag_id": {"type": "keyword"},
                    "name": {
                        "type": "text",
                        "fields": {
                            "keyword": {"type": "keyword"}
                        }
                    },
                    "color": {"type": "keyword"},
                    "description": {"type": "text"},
                    "create_time": {"type": "date"}
                }
            }
        }
        
        # åˆ›å»ºç´¢å¼•
        for index_name, mapping in [
            (self.conversation_index, conversation_mapping),
            (self.message_index, message_mapping),
            (self.tag_index, tag_mapping)
        ]:
            try:
                if not self.es.indices.exists(index=index_name):
                    self.es.indices.create(index=index_name, body=mapping)
                    logger.info(f"âœ… åˆ›å»ºç´¢å¼•: {index_name}")
                else:
                    logger.info(f"ğŸ“‹ ç´¢å¼•å·²å­˜åœ¨: {index_name}")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥ {index_name}: {e}")
                raise
    
    # ==================== å¯¹è¯ç®¡ç† ====================
    
    def save_conversation(self, conversation_id: str, title: str, 
                         platform: str = "chatgpt",
                         create_time: Optional[str] = None,
                         **kwargs) -> bool:
        """ä¿å­˜å¯¹è¯"""
        try:
            doc = {
                "conversation_id": conversation_id,
                "title": title,
                "platform": platform,
                "create_time": create_time or datetime.now().isoformat(),
                "update_time": datetime.now().isoformat(),
                "message_count": kwargs.get("message_count", 0),
                "total_tokens": kwargs.get("total_tokens", 0),
                "model": kwargs.get("model", ""),
                "tags": kwargs.get("tags", []),
                "summary": kwargs.get("summary", ""),
                "category": kwargs.get("category", "")
            }
            
            self.es.index(
                index=self.conversation_index,
                id=conversation_id,
                body=doc,
                refresh=True
            )
            
            logger.info(f"âœ… ä¿å­˜å¯¹è¯: {conversation_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å¯¹è¯å¤±è´¥: {e}")
            return False
    
    def get_conversation(self, conversation_id: str) -> Optional[Dict]:
        """è·å–å¯¹è¯è¯¦æƒ…"""
        try:
            result = self.es.get(index=self.conversation_index, id=conversation_id)
            return result['_source']
        except NotFoundError:
            return None
        except Exception as e:
            logger.error(f"âŒ è·å–å¯¹è¯å¤±è´¥: {e}")
            return None
    
    def list_conversations(self, platform: Optional[str] = None,
                          tags: Optional[List[str]] = None,
                          limit: int = 50,
                          offset: int = 0,
                          sort_by: str = "update_time",
                          order: str = "desc") -> List[Dict]:
        """åˆ—å‡ºå¯¹è¯"""
        try:
            query = {"bool": {"must": []}}
            
            if platform:
                query["bool"]["must"].append({"term": {"platform": platform}})
            
            if tags:
                query["bool"]["must"].append({"terms": {"tags": tags}})
            
            # å¦‚æœæ²¡æœ‰ä»»ä½•æ¡ä»¶ï¼Œä½¿ç”¨match_all
            if not query["bool"]["must"]:
                query = {"match_all": {}}
            
            result = self.es.search(
                index=self.conversation_index,
                body={
                    "query": query,
                    "sort": [{sort_by: {"order": order}}],
                    "from": offset,
                    "size": limit
                }
            )
            
            return [hit['_source'] for hit in result['hits']['hits']]
            
        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºå¯¹è¯å¤±è´¥: {e}")
            return []
    
    def delete_conversation(self, conversation_id: str) -> bool:
        """åˆ é™¤å¯¹è¯"""
        try:
            # åˆ é™¤å¯¹è¯
            self.es.delete(index=self.conversation_index, id=conversation_id, refresh=True)
            
            # åˆ é™¤ç›¸å…³æ¶ˆæ¯
            self.es.delete_by_query(
                index=self.message_index,
                body={"query": {"term": {"conversation_id": conversation_id}}},
                refresh=True
            )
            
            logger.info(f"âœ… åˆ é™¤å¯¹è¯: {conversation_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤å¯¹è¯å¤±è´¥: {e}")
            return False
    
    def update_conversation(self, conversation_id: str, **kwargs) -> bool:
        """æ›´æ–°å¯¹è¯ä¿¡æ¯"""
        try:
            update_doc = {key: value for key, value in kwargs.items() if value is not None}
            update_doc["update_time"] = datetime.now().isoformat()
            
            self.es.update(
                index=self.conversation_index,
                id=conversation_id,
                body={"doc": update_doc},
                refresh=True
            )
            
            logger.info(f"âœ… æ›´æ–°å¯¹è¯: {conversation_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¯¹è¯å¤±è´¥: {e}")
            return False
    
    # ==================== æ¶ˆæ¯ç®¡ç† ====================
    
    def save_message(self, message_id: str, conversation_id: str,
                    role: str, content: str,
                    create_time: Optional[str] = None,
                    **kwargs) -> bool:
        """ä¿å­˜æ¶ˆæ¯"""
        try:
            doc = {
                "message_id": message_id,
                "conversation_id": conversation_id,
                "role": role,
                "content": content,
                "create_time": create_time or datetime.now().isoformat(),
                "order_index": kwargs.get("order_index", 0),
                "parent_message_id": kwargs.get("parent_message_id", ""),
                "tokens": kwargs.get("tokens", 0)
            }
            
            self.es.index(
                index=self.message_index,
                id=message_id,
                body=doc,
                refresh=True
            )
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ¶ˆæ¯å¤±è´¥: {e}")
            return False
    
    def get_messages(self, conversation_id: str,
                    limit: Optional[int] = None) -> List[Dict]:
        """è·å–å¯¹è¯çš„æ‰€æœ‰æ¶ˆæ¯"""
        try:
            query_body = {
                "query": {"term": {"conversation_id": conversation_id}},
                "sort": [{"order_index": {"order": "asc"}}],
                "size": limit or 10000
            }
            
            result = self.es.search(index=self.message_index, body=query_body)
            return [hit['_source'] for hit in result['hits']['hits']]
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ¶ˆæ¯å¤±è´¥: {e}")
            return []
    
    # ==================== æœç´¢åŠŸèƒ½ ====================
    
    def search(self, query: str,
              search_type: str = "full",
              platform: Optional[str] = None,
              tags: Optional[List[str]] = None,
              limit: int = 20,
              offset: int = 0) -> List[Dict]:
        """
        å…¨æ–‡æœç´¢
        
        Args:
            query: æœç´¢å…³é”®è¯
            search_type: æœç´¢ç±»å‹ (full/title/content)
            platform: å¹³å°ç­›é€‰
            tags: æ ‡ç­¾ç­›é€‰
            limit: è¿”å›æ•°é‡
            offset: åç§»é‡
        
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«åŒ¹é…çš„å¯¹è¯å’Œæ¶ˆæ¯
        """
        try:
            results = []
            
            # æœç´¢å¯¹è¯æ ‡é¢˜å’Œæ‘˜è¦
            if search_type in ["full", "title"]:
                conv_results = self._search_conversations(
                    query, platform, tags, limit, offset
                )
                results.extend(conv_results)
            
            # æœç´¢æ¶ˆæ¯å†…å®¹
            if search_type in ["full", "content"]:
                msg_results = self._search_messages(
                    query, platform, tags, limit, offset
                )
                results.extend(msg_results)
            
            # æŒ‰è¯„åˆ†æ’åº
            results.sort(key=lambda x: x.get('score', 0), reverse=True)
            
            return results[:limit]
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def _search_conversations(self, query: str, platform: Optional[str],
                             tags: Optional[List[str]],
                             limit: int, offset: int) -> List[Dict]:
        """æœç´¢å¯¹è¯"""
        try:
            must_clauses = [
                {
                    "multi_match": {
                        "query": query,
                        "fields": ["title^3", "summary^2", "tags"],
                        "type": "best_fields",
                        "operator": "or"
                    }
                }
            ]
            
            if platform:
                must_clauses.append({"term": {"platform": platform}})
            
            if tags:
                must_clauses.append({"terms": {"tags": tags}})
            
            search_body = {
                "query": {"bool": {"must": must_clauses}},
                "highlight": {
                    "fields": {
                        "title": {},
                        "summary": {}
                    },
                    "pre_tags": ["<mark>"],
                    "post_tags": ["</mark>"]
                },
                "from": offset,
                "size": limit
            }
            
            result = self.es.search(index=self.conversation_index, body=search_body)
            
            conversations = []
            for hit in result['hits']['hits']:
                conv = hit['_source'].copy()
                conv['score'] = hit['_score']
                conv['search_type'] = 'conversation'
                conv['highlights'] = hit.get('highlight', {})
                conversations.append(conv)
            
            return conversations
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢å¯¹è¯å¤±è´¥: {e}")
            return []
    
    def _search_messages(self, query: str, platform: Optional[str],
                        tags: Optional[List[str]],
                        limit: int, offset: int) -> List[Dict]:
        """æœç´¢æ¶ˆæ¯å†…å®¹"""
        try:
            # å…ˆæœç´¢æ¶ˆæ¯
            search_body = {
                "query": {
                    "match": {
                        "content": {
                            "query": query,
                            "operator": "or"
                        }
                    }
                },
                "highlight": {
                    "fields": {
                        "content": {
                            "fragment_size": 150,
                            "number_of_fragments": 3
                        }
                    },
                    "pre_tags": ["<mark>"],
                    "post_tags": ["</mark>"]
                },
                "from": offset,
                "size": limit
            }
            
            result = self.es.search(index=self.message_index, body=search_body)
            
            messages = []
            for hit in result['hits']['hits']:
                msg = hit['_source'].copy()
                msg['score'] = hit['_score']
                msg['search_type'] = 'message'
                msg['highlights'] = hit.get('highlight', {})
                
                # è·å–æ‰€å±å¯¹è¯ä¿¡æ¯
                conv = self.get_conversation(msg['conversation_id'])
                if conv:
                    # åº”ç”¨å¹³å°å’Œæ ‡ç­¾ç­›é€‰
                    if platform and conv.get('platform') != platform:
                        continue
                    if tags and not any(tag in conv.get('tags', []) for tag in tags):
                        continue
                    
                    msg['conversation_title'] = conv['title']
                    msg['platform'] = conv['platform']
                    messages.append(msg)
            
            return messages
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢æ¶ˆæ¯å¤±è´¥: {e}")
            return []
    
    # ==================== æ ‡ç­¾ç®¡ç† ====================
    
    def save_tag(self, tag_id: str, name: str, color: str = "#3b82f6",
                description: str = "") -> bool:
        """ä¿å­˜æ ‡ç­¾"""
        try:
            doc = {
                "tag_id": tag_id,
                "name": name,
                "color": color,
                "description": description,
                "create_time": datetime.now().isoformat()
            }
            
            self.es.index(
                index=self.tag_index,
                id=tag_id,
                body=doc,
                refresh=True
            )
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ ‡ç­¾å¤±è´¥: {e}")
            return False
    
    def get_all_tags(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ ‡ç­¾"""
        try:
            result = self.es.search(
                index=self.tag_index,
                body={"query": {"match_all": {}}, "size": 1000}
            )
            
            return [hit['_source'] for hit in result['hits']['hits']]
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ ‡ç­¾å¤±è´¥: {e}")
            return []
    
    def delete_tag(self, tag_id: str) -> bool:
        """åˆ é™¤æ ‡ç­¾"""
        try:
            self.es.delete(index=self.tag_index, id=tag_id, refresh=True)
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤æ ‡ç­¾å¤±è´¥: {e}")
            return False
    
    # ==================== ç»Ÿè®¡åˆ†æ ====================
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = {}
            
            # å¯¹è¯ç»Ÿè®¡
            conv_count = self.es.count(index=self.conversation_index)
            stats['total_conversations'] = conv_count['count']
            
            # æ¶ˆæ¯ç»Ÿè®¡
            msg_count = self.es.count(index=self.message_index)
            stats['total_messages'] = msg_count['count']
            
            # æ ‡ç­¾ç»Ÿè®¡
            tag_count = self.es.count(index=self.tag_index)
            stats['total_tags'] = tag_count['count']
            
            # å¹³å°ç»Ÿè®¡
            platform_agg = self.es.search(
                index=self.conversation_index,
                body={
                    "size": 0,
                    "aggs": {
                        "platforms": {
                            "terms": {"field": "platform"}
                        }
                    }
                }
            )
            
            stats['by_platform'] = {
                bucket['key']: bucket['doc_count']
                for bucket in platform_agg['aggregations']['platforms']['buckets']
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    # ==================== æ‰¹é‡æ“ä½œ ====================
    
    def bulk_save_messages(self, messages: List[Dict]) -> int:
        """æ‰¹é‡ä¿å­˜æ¶ˆæ¯"""
        try:
            actions = []
            for msg in messages:
                action = {
                    "_index": self.message_index,
                    "_id": msg['message_id'],
                    "_source": msg
                }
                actions.append(action)
            
            success, failed = helpers.bulk(self.es, actions, refresh=True)
            logger.info(f"âœ… æ‰¹é‡ä¿å­˜æ¶ˆæ¯: æˆåŠŸ {success}, å¤±è´¥ {len(failed)}")
            return success
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡ä¿å­˜æ¶ˆæ¯å¤±è´¥: {e}")
            return 0
    
    # ==================== æ•°æ®è¿ç§» ====================
    
    def migrate_from_sqlite(self, sqlite_db_path: str) -> Tuple[int, int]:
        """
        ä»SQLiteè¿ç§»æ•°æ®åˆ°Elasticsearch
        
        Returns:
            (æˆåŠŸå¯¹è¯æ•°, æˆåŠŸæ¶ˆæ¯æ•°)
        """
        import sqlite3
        
        try:
            conn = sqlite3.connect(sqlite_db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # è¿ç§»å¯¹è¯
            cursor.execute("SELECT * FROM conversations")
            conversations = cursor.fetchall()
            
            conv_count = 0
            for conv in conversations:
                conv_dict = dict(conv)
                if self.save_conversation(**conv_dict):
                    conv_count += 1
            
            # è¿ç§»æ¶ˆæ¯
            cursor.execute("SELECT * FROM messages")
            messages = cursor.fetchall()
            
            msg_list = [dict(msg) for msg in messages]
            msg_count = self.bulk_save_messages(msg_list)
            
            # è¿ç§»æ ‡ç­¾
            cursor.execute("SELECT * FROM tags")
            tags = cursor.fetchall()
            
            for tag in tags:
                tag_dict = dict(tag)
                self.save_tag(**tag_dict)
            
            conn.close()
            
            logger.info(f"âœ… æ•°æ®è¿ç§»å®Œæˆ: {conv_count}ä¸ªå¯¹è¯, {msg_count}æ¡æ¶ˆæ¯")
            return conv_count, msg_count
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return 0, 0
    
    # ==================== å¥åº·æ£€æŸ¥ ====================
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            cluster_health = self.es.cluster.health()
            
            return {
                "status": cluster_health['status'],
                "cluster_name": cluster_health['cluster_name'],
                "number_of_nodes": cluster_health['number_of_nodes'],
                "active_shards": cluster_health['active_shards'],
                "indices": {
                    "conversations": self.es.count(index=self.conversation_index)['count'],
                    "messages": self.es.count(index=self.message_index)['count'],
                    "tags": self.es.count(index=self.tag_index)['count']
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    def close(self):
        """å…³é—­è¿æ¥"""
        try:
            self.es.close()
            logger.info("âœ… Elasticsearchè¿æ¥å·²å…³é—­")
        except Exception as e:
            logger.error(f"âŒ å…³é—­è¿æ¥å¤±è´¥: {e}")
